
# Artificially Conscious Machines
 
---
Question | Answer |
--- | --- |
Writer | Saurabh Yadav - MSc I year
Editor | Swati Gautam
Status |	Reviewed once. A second opinion required.
Plagiarism |	None.  100% unique.
Added | Sub-headings. Changed the structure.
Content |	Consciousness - Artificial Consciousness - Comparison(what we have so far) - Assessing the future - Conclusion
Verdict | Good Candidate. 
---


## What is consciousness? 
Is it the same as having the ability to think? Or is it like having a soul? Are plants conscious? 
These are some general questions which arise after reading the title. Defining consciousness in words is difficult.

According to Dr Harry H. Porter III, there are roughly three meanings of consciousness[1]:
First, conscious means awake. A person who is asleep or in a coma is said to be unconscious.
Second, the word conscious is often used to mean thinking the way an average human thinks. 
Third, being conscious means being aware of your self and your own thoughts.

## Artificial consciousness
So, what does it mean to have artificial consciousness?  How can we artificially create consciousness if we do not have a precise definition of it? 

An artificially conscious machine could be a machine that possesses the ability to act as humanely as possible and be self-aware of its existence. This ability thus aptly sometimes referred to as machine consciousness or synthetic consciousness. 

To illustrate, say, a machine which can indulge in long conversations, listen to music, have hobbies, embroil in disputes, feel emotions, do mathematics etc.  These characteristics come naturally to a normal human but for a machine, these simple tasks are as difficult as the problem of intergalactic travel for humans.

## A comparison
Today, there are more than 10 million machines(robots) on earth and this number will multiply further in future. All of them excel in their respective tasks. But, to put things into perspective, the number of machines that can truly understand a piece of text, like this very article is stigmatizing. From SHAKEY (so named because of its tendency to tremble during operation), ELIZA to  OpenWorm and Sophia, the world seems to be on a space rocket to achieve better AI machines. Researchers in the past decade have shown some promising results in the field of AI but still, machines are far from achieving **Human Level Artificial Intelligence (HMLI)**.

Nick Bostrom in his book, Superintelligence: Paths, Dangers, Strategies[2] discusses thoroughly, the ways to reach HMLI, it's after effects and challenges. The idea of a truly conscious machine still remains far from reality. Some may argue that Neural Networks have promising results to present but do they even employ real intelligence or are just making simple statistical pattern observation? 
Neural networks are said to emulate the networks of neurons present in our brains. Let us take it into account that someday we will have enough processing power to develop a system capable enough to actually run an artificial brain. Will it have thoughts?  Like the ones we have while eating delicious food or would it just be a fancy elaboration of a simple dot product of vectors matching the labelled output?

## When they are here
Nils Nilsson has devoted a long time working on problems in search, planning, knowledge representation, and robotics. When asked about arrival dates for HLMI, he offered the following opinion[3]: 
>**10% chance: 2030
>50% chance: 2050
>90% chance: 2100** 

Let us be extremely optimistic and believe we will soon develop a machine intelligent enough to pass the Turing Test. Then what? 

We have been raised in an era where sci-fi movies have gone extra miles to showcase what it would be actually like to have an HMLI around. But wait. Don't all these movies show that such a machine is going to end humanity; often referred to as the inevitable “singularity”? All of them present a scenario where such a machine becomes self-aware or rather in attempts of making a sense of reality, tries to kill its own maker. 
From 2001: A Space Odyssey, where HAL (Heuristically programmed Algorithmic computer) gets confused about the orders that were given to it and kills the whole crew of the spaceship to Ex-Machina where Ava becomes self-aware ( “acquires consciousness”) and kills its own maker; we are repeatedly shown the same fate. 
But these are just fictions, right? Or is there a probability that we are going to be doomed by the vicious hand of our own creation? 

## Conclusion
We do not know what a conscious machine is going to be like. We can merely wonder.

Will it be the case that we may not be able to guess if the person sitting in front of us in a coffee shop is a machine or a human? 
Will the machine perceive itself as more evolved? 
Will it possess the ability to comprehend the true meaning of its existence?
(A question, even we ask ourselves)
None of these questions have a definite answer today.
But maybe, in future.       


[1] My Theory of Consciousness: A Summary (http://web.cecs.pdx.edu/~harry/musings/ConscTheory.html)

[2] Superintelligence : Paths, Dangers, Strategies (https://www.amazon.in/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111)

[3] This is again conditional on no civilization-disrupting catastrophe occurring. The definition of HLMI used by Nilsson is “AI able to perform around 80% of jobs as well or better than humans perform” (Kruel 2012).
