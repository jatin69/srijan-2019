# Generative Adversarial Networks (GANs)

---

| Question   | Answer                                                            |
| ---------- | ----------------------------------------------------------------- |
| Writer     | Saurabh Yadav - MSc I year                                        |
| Editor     | Ronak Aggarwal                                                    |
| Status     | Reviewed by Ashita.                                               |
| Plagiarism | None. 100% unique. [Report Link](./plag-reports/plag-gans-v1.pdf) |
| Added      | Formatting, images to be added                                    |
| Content    | Introduction, Comparision from past, links to deep details        |

---
Before starting the article let us try to examine these two images. Is there any discrepancy in these images?

The obvious answer that comes to or mind is no! However, you would be amazed to know that persons in these images do not exist. These images are generated by GANs. At first, the idea of GANs was proposed by Ian Goodfellow in 2014. He is a renowned researcher in the Deep Learning Community and is currently working at OpenAI. Till 2014, GANs were incapable of producing such realistic images, instead, they were far from accurate. Through the years, improvements in algorithms have led us to the point where we might never be able to distinguish between an image of a real person and an image generated by some GANs.


## Why are these GANs so good?

So, unlike any ordinary neural network, GANs consist of two neural networks working opposite to each other where each tries to be better than the other one.

Think it of as a thief who once visited a gallery and saw beautiful painting worth thousands of dollars. He tries to fake it but the gallery has a genius detective who can identify fake paintings in an instant. What does the thief do? He goes to his home and makes the painting every night improving every day to the point where the genius detective cannot recognize the difference between the original painting and the fake one. Thief goes to the gallery and replaces the original one with his own painting, making loads of money in the process. In case of GANs, the thief resembles the neural network called **generator** and the genius detective is called **discriminator**.
The generator is assigned with the task of designing natural looking images, similar to the original ones so that the discriminator can be easily fooled. The generator is given some random noises which it tries to incorporate into making new images, similar to the original one. Then, both original and fake images are sent to the discriminator for checking.

## Are GANs flawless yet?

Certainly not. They have improved throughout the years but it still has some problems like symmetry cannot be seen in faces, background of faces may be inappropriate, distinguishable hair etc.
 
GANs are yet not capable of understanding the image orientation, or other features that can be easily recognized by human eyes. They just try to mimic the image and in doing so, they might end up giving a distorted image. GANs cannot differentiate between foreground and background which in turn makes it difficult to convert a 3D image to 2D. On top of all these shortcomings, the training process also may take quite a lot of time and resources. In short, GANs are better now from the ones in 2014 but still, there's a long way ahead.

There are a lot of inappropriate usages of GANs, as well.
1.	For example, Face2Face model presented at CVPR 2016 can transfer visually plausible facial expressions from a source video to a target video. Using this model, anyone can forge the footage of a country's president and use it inappropriately for their personal benefit.
2.	Another one is PassGAN which has been proposed by Briland Hitaj, Paolo Gasti, Giuseppe Ateniese and Fernando Perez-Cruz in their paper. This project was developed to crack passwords. It performed twice as well as John the ripper and had a very promising result as compared to the contemporary password cracking tools.

There are many more examples to support the statement but we are yet to see a ground-breaking result in this field!

